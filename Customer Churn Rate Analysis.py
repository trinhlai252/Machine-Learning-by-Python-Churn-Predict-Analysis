# -*- coding: utf-8 -*-
"""ML_lastprj_LaiThucTrinh.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1s2LUfySwxbeb1RhCHwal-YVFFQUzZTXG

##Load data
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
import numpy as np
import warnings
import time
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/drive')

path = '/content/drive/MyDrive/Data_ML_Project/'

df= pd.read_excel(path+"churn_prediction.xlsx")
df.head(10)

"""#EDA

##Overview
"""

df.describe()

df.info()

"""đổi tên các cột thành chữ thường

"""

# Đổi tên tất cả các cột trong df thành chữ thường
df.columns = df.columns.str.lower()

df.info()

"""##Check null, check dup"""

null_check =pd.DataFrame({
    'null_count': df.isnull().sum(),
    'null_percentage': df.isnull().sum() * 100/len(df)
})
print(null_check)

col_null = null_check[null_check['null_percentage']>0].index.tolist()
col_null

import math

# Số cột mỗi hàng
num_cols = 4
num_rows = 2

fig, axes = plt.subplots(num_rows, num_cols, figsize=(18, num_rows * 4))
axes = axes.flatten()


for i, col in enumerate(col_null):
    sns.boxplot(x=df[col], ax=axes[i])
    axes[i].set_title(f'Boxplot of {col}')


for j in range(len(col_null), len(axes)):
    fig.delaxes(axes[j])  # Xóa các ô thừa

plt.tight_layout()
plt.show()

"""nhật xét: các cột trên đều tồn tại outliers => replace null = median"""

for col in col_null:
    median_value = df[col].median()  # calculate median
    df[col].fillna(median_value, inplace=True)  #replace

print(df[col_null].isnull().sum())

"""check dup"""

df.duplicated().sum()*100/len(df)

"""check imbalanced"""

label_ratio = df['churn'].value_counts(normalize=True)
label_ratio

"""##Check features"""

#fuction calculate ratio
def calculate_churn_ratio(df, column):
    count_customer = df.groupby(column).agg(
        total_cus=('customerid', 'count'),  # tổng cus
        churn_cus=('churn', 'sum')          # số churn
    ).reset_index()

    count_customer['churn_ratio'] = (count_customer['churn_cus'] / count_customer['total_cus'] * 100).round(2)

    count_customer = count_customer.sort_values(by='churn_ratio', ascending=False)

    return count_customer

"""###Check density of some features: WarehouseToHome, HourSpendOnApp,	CashbackAmount"""

cols = ['warehousetohome', 'hourspendonapp', 'cashbackamount']
num_cols = df[cols]

plt.figure(figsize=(18, 4))

for i, col in enumerate(cols, 1):
    plt.subplot(1, len(cols), i)  # 1 hàng và 3 cột
    sns.kdeplot(num_cols[col], shade=True)
    plt.title(f'Density Distribution of {col}')
    plt.xlabel('Value')
    plt.ylabel('Density')

plt.tight_layout()
plt.show()

cols = ['warehousetohome', 'hourspendonapp', 'cashbackamount']
plt.figure(figsize=(12, 4))

for i, col in enumerate(cols, 1):
    plt.subplot(1, len(cols), i)  # 1 hàng và 3 cột
    sns.boxplot(data=df, x='churn', y=col)

    # Dùng '\n' để xuống dòng trong tiêu đề
    plt.title(f'Distribution of {col}\nbetween Churn and Non-Churn')
    plt.xlabel('Churn')
    plt.ylabel(col)

plt.tight_layout()
plt.show()

"""=>  maybe 3 featues are related to churn

###Check tenure
"""

tenure_churnrate = calculate_churn_ratio(df, 'tenure')
tenure_churnrate.sort_values(by='churn_ratio', ascending=False).head(5)

plt.figure(figsize=(6, 4))
sns.boxplot(data=df, x='churn', y='tenure')
plt.title('Distribution of Tenure between Churn and Non-Churn')
plt.xlabel('Churn')
plt.ylabel('Tenure')
plt.show()

"""=>tenure is related

###Check Citytier
"""

citytier_churnrate = calculate_churn_ratio(df, 'citytier')
citytier_churnrate.sort_values(by='churn_ratio', ascending=False)

"""=> related

###Check Numberofdevice
"""

numberdevide_churnrate = calculate_churn_ratio(df, 'numberofdeviceregistered')
numberdevide_churnrate.sort_values(by='churn_ratio', ascending=False)

"""=> related

###Check satisfactionscore
"""

satisfaction_churnrate = calculate_churn_ratio(df, 'satisfactionscore')
satisfaction_churnrate.sort_values(by='churn_ratio', ascending=False)

"""=>related

###Check numberofaddress
"""

numberaddress_churnrate = calculate_churn_ratio(df, 'numberofaddress')
numberaddress_churnrate.sort_values(by='churn_ratio', ascending=False)

plt.figure(figsize=(6,4))  # Set the size of the plot
sns.boxplot(x=df['numberofaddress'])
plt.title(f'Boxplot of numberofaddress')
plt.show()

"""==>maybe realted

###Check Complain
"""

complain_churnrate = calculate_churn_ratio(df, 'complain')
complain_churnrate.sort_values(by='churn_ratio', ascending=False)

"""=>related

###Check orderamounthike, couponused, ordercount, daysincelastorder
"""

cols = ['orderamounthikefromlastyear', 'couponused', 'ordercount', 'daysincelastorder']
num_cols = df[cols]

plt.figure(figsize=(18, 5))  #

for i, col in enumerate(cols, 1):
    plt.subplot(1, len(cols), i)  # 1 hàng và 4 cột
    sns.boxplot(data=df, x='churn', y=col)

    plt.title(f'Distribution of {col}\nbetween Churn and Non-Churn')

    plt.xlabel('Churn')
    plt.ylabel(col)

plt.tight_layout()
plt.show()

"""orderamounthike,  ordercount is not related. daysincelastorder is related. couponused  maybe relate, need to check more

###Check gender
"""

gender_churnrate= calculate_churn_ratio(df, 'gender')
gender_churnrate

"""=>gender not ralated

###check prefeturedlogindevide
"""

devide_churnrate = calculate_churn_ratio(df, 'preferredlogindevice')
devide_churnrate

"""=> devide related

###Check PreferredPaymentMode
"""

payment_churnrate = calculate_churn_ratio(df, 'preferredpaymentmode')
payment_churnrate.sort_values(by='churn_ratio', ascending=False)

"""=> maybe paymen is ralated

###Check PreferedOrderCat
"""

Ordercat_churnrate = calculate_churn_ratio(df, 'preferedordercat')
Ordercat_churnrate.sort_values(by='churn_ratio', ascending=False)

"""=>maybe preferedorderca is related to churn rate

###Check maritalstatus
"""

marital_churnrate = calculate_churn_ratio(df, 'maritalstatus')
marital_churnrate.sort_values(by='churn_ratio', ascending=False)

"""=> maritalstatus is ralated to churn

#Feature Transforming
"""

list_columns_to_drop = ['customerid','gender','maritalstatus','orderamounthikefromlastyear', 'ordercount']
df_drop = df.drop(columns = list_columns_to_drop)
cate_columns = df_drop.loc[:, df_drop.dtypes == object].columns.tolist()

encoded_df = pd.get_dummies(df_drop, columns = cate_columns,drop_first=True)
encoded_df.head(3)

"""#Model Traning

##Split train/validate/test set
"""

from sklearn.model_selection import train_test_split
x=encoded_df.drop('churn', axis = 1)
y=encoded_df[['churn']]


x_train, x_temp, y_train, y_temp = train_test_split(x,y, test_size=0.3, random_state=42)

x_val, x_test, y_val, y_test = train_test_split(x_temp,y_temp, test_size=0.5, random_state=42)

print(f"Number data of train set: {len(x_train)}")
print(f"Number data of validate set: {len(x_val)}")
print(f"Number data of test set: {len(x_test)}")

"""## Normalization for each set"""

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

scaler.fit(x_train)

x_train_scaled = scaler.transform(x_train)
x_val_scaled = scaler.transform(x_val)
x_test_scaled = scaler.transform(x_test)

"""## Apply Model

###Logistic Regression
"""

from sklearn.linear_model import LogisticRegression

clf_logis = LogisticRegression(random_state = 0)
clf_logis.fit(x_train_scaled, y_train) #model to learn

y_pred_val = clf_logis.predict(x_val_scaled) #model to predict on val set
y_pred_train = clf_logis.predict(x_train_scaled) #Predict back on train to check overfit

"""###Random Forest"""

from sklearn.ensemble import RandomForestClassifier

clf_rand = RandomForestClassifier(max_depth=15, random_state=0, n_estimators = 100)

clf_rand.fit(x_train_scaled, y_train)

y_ranf_pre_train = clf_rand.predict(x_train_scaled) #Predict back on train to check overfit
y_ranf_pre_val = clf_rand.predict(x_val_scaled) #Model to predict on val set

"""#Model Evaluation"""

from sklearn.metrics import balanced_accuracy_score, f1_score
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

"""##Logistic Regression"""

balanced_accuracy_train = balanced_accuracy_score(y_train, y_pred_train)
balanced_accuracy_val = balanced_accuracy_score(y_val, y_pred_val)
print(balanced_accuracy_train,balanced_accuracy_val)

cm = confusion_matrix(y_val, y_pred_val, labels=clf_logis.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=clf_logis.classes_)
disp.plot()

"""##Random Forest"""

balanced_accuracy_train = balanced_accuracy_score(y_train, y_ranf_pre_train)
balanced_accuracy_val = balanced_accuracy_score(y_val, y_ranf_pre_val)
print(balanced_accuracy_train,balanced_accuracy_val)

"""=> sử dụng random forest

##Hyperparameter Tuning
"""

from sklearn.model_selection import GridSearchCV
# Xác định các params để GridSearch chạy qua thử (
param_grid = {
    'n_estimators': [10, 50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'bootstrap': [True, False]
}

# Use GridSearchCV to find the best parameters
grid_search = GridSearchCV(clf_rand, param_grid, cv=5, scoring='balanced_accuracy')

# Fit the model
grid_search.fit(x_train, y_train)

# Print the best parameters
print("Best Parameters: ", grid_search.best_params_)

# Evaluate the best model on the test set
best_clf = grid_search.best_estimator_
accuracy = best_clf.score(x_test, y_test)
print("Test set accuracy: ", accuracy)

best_params = grid_search.best_params_
clf_rand_after = RandomForestClassifier(**best_params,random_state=0)

clf_rand_after.fit(x_train, y_train)
y_ranf_aft_train = clf_rand_after.predict(x_train)
y_ranf_aft_val = clf_rand_after.predict(x_val)

print(f'Balance accuracy of train set: {balanced_accuracy_score(y_train, y_ranf_aft_train)}')
print(f'Balance accuracy of val set: {balanced_accuracy_score(y_val, y_ranf_aft_val)}')

